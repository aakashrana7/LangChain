{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMshR6YeMVsbKa8n0fYA0gh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakashrana7/LangChain/blob/main/Langchain_Class2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-Shot Prompting (LangChain)\n",
        "\n",
        "Meaning:\n",
        "Few-shot prompting is when you give an LLM a few examples of the input and output format inside the prompt so it learns from them and generates answers in the same style.\n",
        "It’s like saying: “Here are some examples. Now do the same for this new case.”\n",
        "\n",
        "Few-Shot Prompt Template in LangChain\n",
        "\n",
        "In LangChain, you can use FewShotPromptTemplate to automatically insert multiple examples into a single prompt.\n",
        "\n",
        "Main parameters:\n",
        "\n",
        "examples → A list of dictionaries with your example input/output.\n",
        "\n",
        "example_prompt → A PromptTemplate that formats how each example looks.\n",
        "\n",
        "prefix → Text that comes before the examples (e.g., instructions).\n",
        "\n",
        "suffix → Text that comes after the examples (usually the real question).\n",
        "\n",
        "input_variables → Variables in the suffix that will be filled with user input."
      ],
      "metadata": {
        "id": "qS9RB9QiI-5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z4_0SdwI5i1"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "# 1. Define how each example looks\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answer\"],\n",
        "    template=\"Q: {question}\\nA: {answer}\"\n",
        ")\n",
        "\n",
        "# 2. Provide few-shot examples\n",
        "examples = [\n",
        "    {\"question\": \"Capital of France?\", \"answer\": \"Paris\"},\n",
        "    {\"question\": \"Capital of Japan?\", \"answer\": \"Tokyo\"},\n",
        "]\n",
        "\n",
        "# 3. Create the FewShotPromptTemplate\n",
        "few_shot = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Answer the following questions:\",\n",
        "    suffix=\"Q: {user_question}\\nA:\",\n",
        "    input_variables=[\"user_question\"]\n",
        ")\n",
        "\n",
        "# 4. Format the final prompt\n",
        "print(few_shot.format(user_question=\"Capital of Nepal?\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building prompts for sequential chains\n"
      ],
      "metadata": {
        "id": "-8-uYgoBJI6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template that takes an input activity\n",
        "learning_prompt = PromptTemplate(\n",
        "    input_variables=[\"activity\"],\n",
        "    template=\"I want to learn how to {activity}. Can you suggest how I can learn this step-by-step?\"\n",
        ")\n",
        "\n",
        "# Create a prompt template that places a time constraint on the output\n",
        "time_prompt = PromptTemplate(\n",
        "    input_variables=[\"learning_plan\"],\n",
        "    template=\"I only have one week. Can you create a plan to help me hit this goal: {learning_plan}.\"\n",
        ")\n",
        "\n",
        "# Invoke the learning_prompt with an activity\n",
        "print(learning_prompt.invoke({\"activity\": \"play_golf\"}))"
      ],
      "metadata": {
        "id": "2UZX0P4-LaqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential chains with LCEL\n"
      ],
      "metadata": {
        "id": "QI2t2mo4Ldsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_prompt = PromptTemplate(\n",
        "    input_variables=[\"activity\"],\n",
        "    template=\"I want to learn how to {activity}. Can you suggest how I can learn this step-by-step?\"\n",
        ")\n",
        "\n",
        "time_prompt = PromptTemplate(\n",
        "    input_variables=[\"learning_plan\"],\n",
        "    template=\"I only have one week. Can you create a concise plan to help me hit this goal: {learning_plan}.\"\n",
        ")\n",
        "\n",
        "# Complete the sequential chain with LCEL\n",
        "seq_chain = ({\"learning_plan\": learning_prompt | llm | StrOutputParser()}\n",
        "    | time_prompt\n",
        "    | llm\n",
        "    | StrOutputParser())\n",
        "\n",
        "# Call the chain\n",
        "print(seq_chain.invoke({\"activity\": \"play the harmonica\"}))"
      ],
      "metadata": {
        "id": "z_b6ES-1Lhsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG\n"
      ],
      "metadata": {
        "id": "7jwXXynMMnz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Document Loaders"
      ],
      "metadata": {
        "id": "h6DQ5y9tiND3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf unstructured\n"
      ],
      "metadata": {
        "id": "rJS-sE4Ghx8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"path/to/file/attention_is_all_you_need.pdf\")\n",
        "data = loader.load()\n",
        "print(data[0])\n"
      ],
      "metadata": {
        "id": "BBN1i1Rhh-qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "loader = CSVLoader('fifa_countries_audience.csv')\n",
        "data = loader.load()\n",
        "print(data[0])\n"
      ],
      "metadata": {
        "id": "qQMh7Ilhh_Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import Unstructured\n",
        "\n",
        "HTMLLoaderloader = UnstructuredHTMLLoader(\"white_house_executive_order_nov_2023.html\")\n",
        "\n",
        "data = loader.load()\n",
        "print(data[0])\n",
        "print(data[0].metadata)"
      ],
      "metadata": {
        "id": "DEVo8xyzic3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Splitting external data for retrieval\n",
        "\n"
      ],
      "metadata": {
        "id": "O9z8oXwCiq1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">using CharacterTextSplitter for single separator\n",
        "\n"
      ],
      "metadata": {
        "id": "83A7kdz5jrGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the character splitter\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "quote = 'Words are flowing out like endless rain into a paper cup,\\nthey slither while they pass,\\nthey slip away across the universe.'\n",
        "chunk_size = 24\n",
        "chunk_overlap = 10\n",
        "\n",
        "# Create an instance of the splitter class\n",
        "splitter = CharacterTextSplitter(\n",
        "    separator='\\n',\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "\n",
        "# Split the string and print the chunks\n",
        "docs = splitter.split_text(quote)\n",
        "print(docs)\n",
        "print([len(doc) for doc in docs])"
      ],
      "metadata": {
        "id": "oJgSu_8xir1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">using RecursiveCharacterTextSplitter for multiple separator left to right"
      ],
      "metadata": {
        "id": "ggb0ZvWyj1Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the recursive character splitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "quote = 'Words are flowing out like endless rain into a paper cup,\\nthey slither while they pass,\\nthey slip away across the universe.'\n",
        "chunk_size = 24\n",
        "chunk_overlap = 10\n",
        "\n",
        "# Create an instance of the splitter class\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "\n",
        "# Split the document and print the chunks\n",
        "docs = splitter.split_text(quote)\n",
        "print(docs)\n",
        "print([len(doc) for doc in docs])"
      ],
      "metadata": {
        "id": "lWcR0Difjj9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the HTML document into memory\n",
        "loader = UnstructuredHTMLLoader('white_house_executive_order_nov_2023.html')\n",
        "data = loader.load()\n",
        "\n",
        "# Define variables\n",
        "chunk_size = 300\n",
        "chunk_overlap = 100\n",
        "\n",
        "# Split the HTML\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separators=['.'])\n",
        "\n",
        "docs = splitter.split_documents(data)\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "BZ7KsTkGkyMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Storage and Retrieval"
      ],
      "metadata": {
        "id": "w_wLefcpl6ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader('rag_vs_fine_tuning.pdf')\n",
        "data = loader.load()\n",
        "\n",
        "# Split the document using RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "docs = splitter.split_documents(data)\n",
        "\n",
        "# Embed the documents in a persistent Chroma vector database\n",
        "embedding_function = OpenAIEmbeddings(api_key='<OPENAI_API_TOKEN>', model='text-embedding-3-small')\n",
        "vectorstore = Chroma.from_documents(\n",
        "    docs,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=os.getcwd()\n",
        ")\n",
        "\n",
        "# Configure the vector store as a retriever\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3}\n",
        ")"
      ],
      "metadata": {
        "id": "f4RVP65bl9kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    docs,\n",
        "    embedding=OpenAIEmbeddings(api_key='<OPENAI_API_TOKEN>', model='text-embedding-3-small'),\n",
        "    persist_directory=os.getcwd()\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3}\n",
        ")\n",
        "\n",
        "# Create a chain to link retriever, prompt_template, and llm\n",
        "rag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "            | prompt_template\n",
        "            | llm)\n",
        "\n",
        "# Invoke the chain\n",
        "response = rag_chain.invoke(\"Which popular LLMs were considered in the paper?\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "lX8eHoLHmHfr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}